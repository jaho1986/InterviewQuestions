What can Kubernetes do for you?
With modern web services, users expect applications to be available 24/7, and developers expect to deploy new versions of those applications several times a day. Containerization helps package software to serve these goals, enabling applications to be released and updated without downtime. Kubernetes helps you make sure those containerized applications run where and when you want, and helps them find the resources and tools they need to work. Kubernetes is a production-ready, open source platform designed with Google's accumulated experience in container orchestration, combined with best-of-breed ideas from the community.

Kubernetes Clusters
Kubernetes coordinates a highly available cluster of computers that are connected to work as a single unit. The abstractions in Kubernetes allow you to deploy containerized applications to a cluster without tying them specifically to individual machines. Kubernetes automates the distribution and scheduling of application containers across a cluster in a more efficient way. The Control Plane is responsible for managing the cluster. The Control Plane coordinates all activities in your cluster, such as scheduling applications, maintaining applications' desired state, scaling applications, and rolling out new updates.

The Control Plane 
Is responsible for managing the cluster. The Control Plane coordinates all activities in your cluster, such as scheduling applications, maintaining applications' desired state, scaling applications, and rolling out new updates.

A node 
Is a VM or a physical computer that serves as a worker machine in a Kubernetes cluster. Each node has a Kubelet, which is an agent for managing the node and communicating with the Kubernetes control plane. The node should also have tools for handling container operations, such as containerd or Docker. A Kubernetes cluster that handles production traffic should have a minimum of three nodes.

When you deploy applications on Kubernetes, you tell the control plane to start the application containers. The control plane schedules the containers to run on the cluster's nodes. The nodes communicate with the control plane using the Kubernetes API, which the control plane exposes. End users can also use the Kubernetes API directly to interact with the cluster.

View our app:
The kubectl command can create a proxy that will forward communications into the cluster-wide, private network.
The API server will automatically create an endpoint for each pod, based on the pod name, that is also accessible through the proxy.

First we need to get the Pod name, and we'll store in the environment variable POD_NAME:
export POD_NAME=$(kubectl get pods -o go-template --template '{{range .items}}{{.metadata.name}}{{"\n"}}{{end}}')
echo Name of the Pod: $POD_NAME

You can access the Pod through the API by running:
curl http://localhost:8001/api/v1

Kubernetes Pods:
When you created a Deployment in Module 2, Kubernetes created a Pod to host your application instance. A Pod is a Kubernetes abstraction that represents a group of one or more application containers (such as Docker), and some shared resources for those containers. Those resources include:
 - Shared storage, as Volumes
 - Networking, as a unique cluster IP address
 - Information about how to run each container, such as the container image version or specific ports to use

Pods are the atomic unit on the Kubernetes platform. When we create a Deployment on Kubernetes, that Deployment creates Pods with containers inside them (as opposed to creating containers directly). Each Pod is tied to the Node where it is scheduled, and remains there until termination (according to restart policy) or deletion. In case of a Node failure, identical Pods are scheduled on other available Nodes in the cluster.


Nodes:
A Pod always runs on a Node. A Node is a worker machine in Kubernetes and may be either a virtual or a physical machine, depending on the cluster. Each Node is managed by the control plane. A Node can have multiple pods, and the Kubernetes control plane automatically handles scheduling the pods across the Nodes in the cluster. The control plane's automatic scheduling takes into account the available resources on each Node.
Every Kubernetes Node runs at least:
 - Kubelet, a process responsible for communication between the Kubernetes control plane and the Node; it manages the Pods and the containers running on a machine.
 - A container runtime (like Docker) responsible for pulling the container image from a registry, unpacking the container, and running the application.

Executing command on the container:
We can execute commands directly on the container once the Pod is up and running. For this, we use the exec command and use the name of the Pod as a parameter. Let’s list the environment variables:
kubectl exec $POD_NAME -- env

Next let’s start a bash session in the Pod’s container:
kubectl exec -ti $POD_NAME -- bash

Next, let’s scale the Deployment to 4 replicas. We’ll use the kubectl scale command, followed by the deployment type, name and desired number of instances:
kubectl scale deployments/kubernetes-bootcamp --replicas=4

Next, let’s check if the number of Pods changed:
kubectl get pods -o wide

The change was registered in the Deployment events log. To check that, use the describe command:
kubectl describe deployments/kubernetes-bootcamp

Let’s check that the Service is load-balancing the traffic. To find out the exposed IP and Port we can use the describe service as we learned in the previous Module:
kubectl describe services/kubernetes-bootcamp

To scale down the Service to 2 replicas, run again the scale command:
kubectl scale deployments/kubernetes-bootcamp --replicas=2

The number of replicas decreased to 2. List the number of Pods, with get pods:
kubectl get pods -o wide

To update the image of the application to version 2, use the set image command, followed by the deployment name and the new image version:
kubectl set image deployments/kubernetes-bootcamp kubernetes-bootcamp=jocatalin/kubernetes-bootcamp:v2

First, check that the app is running. To find the exposed IP and Port, run the describe service command:
kubectl describe services/kubernetes-bootcamp

Create an environment variable called NODE_PORT that has the value of the Node port assigned:
export NODE_PORT=$(kubectl get services/kubernetes-bootcamp -o go-template='{{(index .spec.ports 0).nodePort}}')
echo NODE_PORT=$NODE_PORT

You can also confirm the update by running the rollout status command:
kubectl rollout status deployments/kubernetes-bootcamp

To view the current image version of the app, run the describe pods command:
kubectl describe pods

Let’s perform another update, and deploy an image tagged with v10 :
kubectl set image deployments/kubernetes-bootcamp kubernetes-bootcamp=gcr.io/google-samples/kubernetes-bootcamp:v10

To roll back the deployment to your last working version, use the rollout undo command:
kubectl rollout undo deployments/kubernetes-bootcamp

Persistent Volume:
PV is how we map external storage into our cluster.


Persistent Volume claim:
It's how a pod ask for a persistent volume.

kubectl create deployment -> create: deployment, replicaset & pod
kubectl expose deployment -> create: service

----------------------------------------------------
With GoogleCloud:
----------------------------------------------------
Connect to the cluster:
gcloud container clusters get-credentials <name_of_cluster> --zone us-central1-c --project <project_id>

Create deployment:
kubectl create deployment <name_of_deplyment> --image=<image_path>

Expose deployment:
kubectl expose deployment <name_of_deplyment> --type=LoadBalancer --port=8080

Get log of changes:
kubectl get events --sort-by=.metadata.creationTimestamp

Set nodes to zero:
gcloud container clusters resize --zone us-central1-c jaho-cluster-1 --num-nodes=0

Set number of replicas:
kubectl scale deployment hello-world-rest-api --replicas=3

How to deploy a new version:
kubectl set image deployment <nameOfDeployment> <nameOfContainer>=<imageName>:version

How to kill a pod:
kubectl delete pod <podId>

Deployment history:
kubectl rollout history deployment <name_of_deplyment>

Undo deployment:
kubectl rollout undo deplyment <name_of_deplyment> --to-revision=<numberOfRevision>

Get status of deployment:
kubectl rollout status deployment <name_of_deplyment>

Get logs:
kubect logs <POD_ID> -f

Get YAML configuration of deplyment:
kubectl get deployment <name_of_deplyment> -o yaml

Get YAML configuration of deplyment to file:
kubectl get deployment <name_of_deplyment> -o yaml > deployment.yaml

Apply YAML condiguration to deployment:
kubectl apply -f deployment.yaml

Delete deployment:
kubectl delete all -l app=<name_of_deplyment>

Get difference between the existing deployment and the new one:
kubectl diff -f deployment.yaml

Get all namespaces from a pod:
kubectl get pods --all-namespaces

Get list of persistent volume configured:
kubectl get pv

Get list of persistent volume claims configured:
kubectl get pvc

Create a configmap:
kubectl create configmap <NameOfConfigMap> --from-literal=RDS_DB_NAME=mysql

Get configmap:
kubectl get configmap <NameOfConfigMap>
kubectl describe <NameOfConfigMap>

Store a password in Kubernetes:
kubectl create secret generic <secretName> --from-literal=RDS_PASSWORD=<yourPassword>

Get passwords store:
kubectl get <secretName>

Delete a service:
kubectl delete service <nserviceName>

Create a ClusterIP Kubernetes Service for MySQL DB:


Commands:
minikube version
minikube start
kubectl version
kubectl cluster-info
kubectl get nodes
kubectl create deployment kubernetes-bootcamp --image=gcr.io/google-samples/kubernetes-bootcamp:v1
kubectl get deployments
kubectl get - list resources
kubectl describe - show detailed information about a resource
kubectl logs - print the logs from a container in a pod
kubectl exec - execute a command on a container in a pod
kubectl describe pods - We see here details about the Pod’s container: IP address, the ports used and a list of events related to the lifecycle of the Pod.
